{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a hands-on code walkthrough of how \"add & layer normalization\" is defined."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer Normalization\n",
    "- Why? The activation of neurons in a neural network, are varying and often large positive and negative values. Layer Normalization helps in stabilizing these values around a mean of 0, and a standard deviation, to improve model performance. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How yHat is usually calculated:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ yHat = w^T * X + B $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How yHat is calculated with Layer Normalization. In the below formula, gamma and bias term are also \"learnable\" parameters of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ yPred = \\gamma \\biggl({\\frac{yHat - \\mu}{\\sigma}} \\biggr) + B $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layer normalization is done, on the output of the multi-headed attention step, \n",
    "# which outputs a set of embeddings. The below code, creates a random tensor of \n",
    "# \"1 batch-size\" to showcase how parallelization can be incorporated, number of \n",
    "# words as 2, and number of arbitrary embeddings as 3, for each of the 2 words.\n",
    "\n",
    "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
    "batch_size, number_of_words, embeddings = inputs.size()\n",
    "inputs = inputs.reshape(number_of_words, batch_size, embeddings)\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_shape = inputs.size()[-2:]\n",
    "\n",
    "# Define the gamma and bias/beta terms which are trainable parameters of the layer normalization process\n",
    "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "beta = nn.Parameter(torch.zeros(parameter_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.size(), beta.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims = [-(i+1) for i in range(len(parameter_shape))]\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = inputs.mean(dim=dims, keepdim=True)\n",
    "mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2000]],\n",
       "\n",
       "        [[0.2333]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0817]],\n",
       "\n",
       "        [[0.1886]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "epsilon = 1e-5\n",
    "std = (var + epsilon).sqrt()\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
       "\n",
       "        [[ 1.4140, -0.7070, -0.7070]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPred = (inputs - mean) / std\n",
    "yPred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining everything above to create re-usable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization:\n",
    "    \n",
    "    def __init__(self, parameter_shape, eps=1e-5):\n",
    "        self.parameters_shape = parameter_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(parameter_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        dims = [-(i+1) for i in range(len(self.parameters_shape))]\n",
    "        mean = inputs.mean(dim=dims, keepdim=True)\n",
    "        print(\"mean is: \", mean)\n",
    "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        print(\"std is: \", std)\n",
    "        yPred = (inputs - mean) / std\n",
    "        print(\"yPred is: \", yPred)\n",
    "        out = self.gamma * yPred + self.beta\n",
    "        print(\"out is: \", out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Sample 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
    "batch_size, number_of_words, embeddings = inputs.size()\n",
    "inputs = inputs.reshape(number_of_words, batch_size, embeddings)\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean is:  tensor([[[0.2000]],\n",
      "\n",
      "        [[0.2333]]])\n",
      "std is:  tensor([[[0.0817]],\n",
      "\n",
      "        [[0.1886]]])\n",
      "yPred is:  tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
      "\n",
      "        [[ 1.4140, -0.7070, -0.7070]]])\n",
      "out is:  tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
      "\n",
      "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNormalization(inputs.size()[-2:])\n",
    "out = ln.forward(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Sample 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 3 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 3\n",
    "sentence_length = 5\n",
    "embeeddings_dim = 8\n",
    "\n",
    "inputs = torch.randn(sentence_length, batch_size, embeeddings_dim)\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0384,  0.5514, -1.7740, -0.8103, -0.3624, -0.0891,  1.1995,\n",
       "           0.1242],\n",
       "         [-0.3968,  0.6609, -0.2462,  0.8967,  0.0881,  0.7868,  0.5733,\n",
       "           1.0558],\n",
       "         [-0.0509, -0.5829,  0.3879, -0.2013,  0.0669, -0.2171,  3.5800,\n",
       "          -0.8869]],\n",
       "\n",
       "        [[ 1.8947, -0.0449,  0.1689, -1.0628, -0.0268,  1.4316, -1.1890,\n",
       "           0.4034],\n",
       "         [-0.1751,  0.1311, -0.8976,  0.3440,  0.0097,  0.7959, -1.1326,\n",
       "          -0.1315],\n",
       "         [ 1.0377,  0.3952,  2.8899, -1.3676, -0.8985,  0.4896, -0.3504,\n",
       "           1.3439]],\n",
       "\n",
       "        [[ 0.6586, -0.4266, -0.9415,  0.4833,  1.3271,  0.1943,  0.5293,\n",
       "          -0.5305],\n",
       "         [ 0.4919,  0.8674,  1.4671, -1.2163, -0.0985,  0.9991, -0.1465,\n",
       "          -0.4534],\n",
       "         [ 1.1036,  0.1054,  0.2652, -2.4811,  1.2961,  0.2491, -1.5688,\n",
       "           0.0838]],\n",
       "\n",
       "        [[-1.3049,  0.4179,  0.9155, -1.6621, -0.0244, -0.5019,  0.6881,\n",
       "           1.0417],\n",
       "         [-0.7131,  0.7899, -1.0207, -0.2845, -0.3761, -0.1282,  0.6376,\n",
       "          -0.7572],\n",
       "         [-1.5257, -1.0551, -0.3540,  1.9730, -1.4110, -0.2243, -0.2415,\n",
       "          -0.4988]],\n",
       "\n",
       "        [[ 0.3958, -0.0284,  2.2852,  1.4316,  0.9404,  0.2143, -0.9799,\n",
       "           0.1501],\n",
       "         [ 1.2311, -0.2992, -2.4002,  0.3274, -1.8527,  3.1699, -0.1631,\n",
       "           0.6587],\n",
       "         [-0.1157, -1.0523, -2.2260, -0.5524, -0.8528,  1.8278, -0.4689,\n",
       "          -2.0858]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LayerNormalization(inputs.size()[-2:])\n",
    "out = ln.forward(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
